{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Middleware Project: Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import operator\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize spark\n",
    "sc = pyspark.SparkContext(\"local[4]\", \"MiddlewareProject\")  # 4 threads\n",
    "spark = SparkSession.builder.appName(\"MiddlewareProject\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test vari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come aprire un file\n",
    "df = spark.read.csv(DATASET_DIR + 'short.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Year='1994', Month='1', DayofMonth='7', DayOfWeek='5', DepTime='858', CRSDepTime='900', ArrTime='954', CRSArrTime='1003', UniqueCarrier='US', FlightNum='227', TailNum='NA', ActualElapsedTime='56', CRSElapsedTime='63', AirTime='NA', ArrDelay='-9', DepDelay='-2', Origin='CLT', Dest='ORF', Distance='290', TaxiIn='NA', TaxiOut='NA', Cancelled='0', CancellationCode='NA', Diverted='0', CarrierDelay='NA', WeatherDelay='NA', NASDelay='NA', SecurityDelay='NA', LateAircraftDelay='NA')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roba con dataframe\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'NA' with null values\n",
    "df = df.replace('NA', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepTime           -> 5754\n",
      "ArrTime           -> 6135\n",
      "TailNum           -> 100000\n",
      "ActualElapsedTime -> 6135\n",
      "AirTime           -> 100000\n",
      "ArrDelay          -> 6135\n",
      "DepDelay          -> 5754\n",
      "TaxiIn            -> 100000\n",
      "TaxiOut           -> 100000\n",
      "CancellationCode  -> 100000\n",
      "CarrierDelay      -> 100000\n",
      "WeatherDelay      -> 100000\n",
      "NASDelay          -> 100000\n",
      "SecurityDelay     -> 100000\n",
      "LateAircraftDelay -> 100000\n"
     ]
    }
   ],
   "source": [
    "# find columns with null values\n",
    "for col in df.columns:\n",
    "    num = df.filter(df[col].isNull()).count()\n",
    "    if num > 0:\n",
    "        print(\"{:17} -> {}\".format(col, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast columns to correct type\n",
    "intcolumns = ['Year', 'Month', 'DayofMonth', 'DayofWeek', 'DepTime', 'CRSDEPTime', 'ArrTime', 'CRSArrTime',\n",
    "              'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Distance', 'CarrierDelay',\n",
    "              'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'Cancelled', 'Diverted']\n",
    "\n",
    "for c in intcolumns:\n",
    "    df = df.withColumn(c, df[c].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Year=1994, Month=1, DayofMonth=7, DayofWeek=5, DepTime=858, CRSDEPTime=900, ArrTime=954, CRSArrTime=1003, UniqueCarrier='US', FlightNum='227', TailNum=None, ActualElapsedTime=56, CRSElapsedTime=63, AirTime=None, ArrDelay=-9, DepDelay=-2, Origin='CLT', Dest='ORF', Distance=290, TaxiIn=None, TaxiOut=None, Cancelled=0, CancellationCode=None, Diverted=0, CarrierDelay=None, WeatherDelay=None, NASDelay=None, SecurityDelay=None, LateAircraftDelay=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to pandas dataframe\n",
    "# dfpd = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfpd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfpd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/rdd-programming-guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: ./dataset/{2004}.csv\n",
      "Number of entries: 7129270\n"
     ]
    }
   ],
   "source": [
    "# years = range(1994, 2009)\n",
    "years = range(2004, 2005)\n",
    "path = DATASET_DIR + '{' + ','.join(str(y) for y in years) + '}.csv'\n",
    "print('Loading from:', path)\n",
    "\n",
    "# load entire file\n",
    "df = spark.read.csv(path, header=True)\n",
    "print('Number of entries:', df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'NA' with null values\n",
    "df = df.replace('NA', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Year=2004, Month=1, DayofMonth=12, DayofWeek=1, DepTime=623, CRSDEPTime=630, ArrTime=901, CRSArrTime=915, UniqueCarrier='UA', FlightNum='462', TailNum='N805UA', ActualElapsedTime=98, CRSElapsedTime=105, AirTime=80, ArrDelay=-14, DepDelay=-7, Origin='ORD', Dest='CLT', Distance=599, TaxiIn='7', TaxiOut='11', Cancelled=0, CancellationCode=None, Diverted=0, CarrierDelay=0, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast columns to correct type\n",
    "intcolumns = ['Year', 'Month', 'DayofMonth', 'DayofWeek', 'DepTime', 'CRSDEPTime', 'ArrTime', 'CRSArrTime',\n",
    "              'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Distance', 'CarrierDelay',\n",
    "              'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'Cancelled', 'Diverted']\n",
    "\n",
    "for c in intcolumns:\n",
    "    df = df.withColumn(c, df[c].cast('int'))\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of canceled flights per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the percentage of canceled flights per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly percentages of delays due to weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# get RDD\n",
    "raw_data = df.rdd\n",
    "\n",
    "# filter out flights with no arrival delay\n",
    "delayed_flights = raw_data.filter(lambda r: r['ArrDelay'] is not None and r['ArrDelay'] > 0)\n",
    "\n",
    "# add the week as key\n",
    "def find_week(row):\n",
    "    '''Returns the week as a tuple (year, week in the year)'''\n",
    "    d = datetime(year=row['Year'], month=row['Month'], day=row['DayofMonth'])\n",
    "    ic = d.isocalendar()\n",
    "    return (ic[0], ic[1])\n",
    "\n",
    "indexed_by_week = delayed_flights.map(lambda r: (find_week(r), r))\n",
    "\n",
    "# check for each flight if it had any weather delay\n",
    "# also map to 1 to count delayed flights\n",
    "flight_delays = indexed_by_week.map(lambda t: (t[0], (1, 1 if t[1]['WeatherDelay'] else 0)))\n",
    "\n",
    "# count number flights with delay and number of flights with weather delay, for each week\n",
    "num_delays = flight_delays.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
    "\n",
    "# compute percentage of weather delays over all delayed flights, for each week\n",
    "weather_delay_ratios = num_delays.map(lambda t: (t[0], 100 * t[1][1] / t[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 57.835 seconds\n"
     ]
    }
   ],
   "source": [
    "# execute query\n",
    "starttime = time()\n",
    "res = weather_delay_ratios.collect()\n",
    "endtime = time() - starttime\n",
    "print('Time taken: {:.5} seconds'.format(endtime))\n",
    "\n",
    "# order in cronological order\n",
    "res = sorted(res, key=lambda x: x[0][0]*53 + x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((2004, 1), 5.62224301563962), ((2004, 2), 4.541806567848661), ((2004, 3), 4.810908625637464), ((2004, 4), 3.5868844789270535), ((2004, 5), 6.811728191243478), ((2004, 6), 5.502487404040243), ((2004, 7), 3.408539543910723), ((2004, 8), 1.7978157378885466), ((2004, 9), 4.413975082668092), ((2004, 10), 3.3621790324868774)]\n"
     ]
    }
   ],
   "source": [
    "print(res[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO visualizzazione\n",
    "# plot per settimana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"a week\" = tutti i voli con orario di partenza in quella settimana\n",
    "## \"delay\" interpreto come arrival delay. \n",
    "## Testato, non ci sono weather delay che vengono \"recuperati\" all'arrivo\n",
    "\n",
    "## versione 1: (accettata dal prof) <---\n",
    "# numero di voli con any weather delay / numero di voli con ritardo\n",
    "\n",
    "## versione 2: (versione \"pesata\")\n",
    "# per ogni volo, se ha ritardo, fai weather delay / ritardo volo\n",
    "# fai media\n",
    "\n",
    "## versione 3: (aggregata)\n",
    "# totale weather delay / totale ritardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay reduced per distance group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the percentage of flights belonging to a given \"distance group\"\n",
    "# that were able to halve their departure delays by the time they \n",
    "# arrived at their destinations. \n",
    "\n",
    "# Distance groups assort flights by their total distance in miles.\n",
    "# Flights with distances that are less than 200 miles belong in group 1,\n",
    "# flights with distances that are between 200 and 399 miles belong \n",
    "# in group 2, flights with distances that are between 400 and 599 miles\n",
    "# belong in group 3, and so on. The last group contains flights whose\n",
    "# distances are between 2400 and 2599 miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RDD\n",
    "raw_data = df.rdd\n",
    "\n",
    "# take only flights with a departure delay\n",
    "late_departures = raw_data.filter(lambda r: r['DepDelay'] is not None and r['DepDelay'] > 0)\n",
    "\n",
    "# add distance group as key\n",
    "def distance_group(row):\n",
    "    distance = row['Distance']\n",
    "    return (distance // 200) + 1\n",
    "    \n",
    "distance_groups = late_departures.map(lambda r: (distance_group(r), r))\n",
    "\n",
    "# check for each flight if it managed to halve its departure delay\n",
    "# also map to 1 to count flights\n",
    "def was_delay_halved(row):\n",
    "    departure_delay = row['DepDelay']\n",
    "    arrival_delay = row['ArrDelay']\n",
    "    if arrival_delay is None:\n",
    "        # missing data\n",
    "        return False\n",
    "    gain = departure_delay - arrival_delay\n",
    "    return gain >= departure_delay / 2\n",
    "\n",
    "halved_delays = distance_groups.map(lambda t: (t[0], (1, was_delay_halved(t[1]))))\n",
    "\n",
    "# count number of delayed flights and number of flights with halved delay\n",
    "totals = halved_delays.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
    "\n",
    "# compute percentage per distance group\n",
    "halving_percentages = totals.map(lambda t: (t[0], 100 * t[1][1] / t[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 52.432 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5d38b628e109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# order in cronological order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m53\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-5d38b628e109>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# order in cronological order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m53\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# execute query\n",
    "starttime = time()\n",
    "res = halving_percentages.collect()\n",
    "endtime = time() - starttime\n",
    "print('Time taken: {:.5} seconds'.format(endtime))\n",
    "\n",
    "# sort by distance group\n",
    "res = sorted(res, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 < d <  200 miles --> 24.87%\n",
      " 200 < d <  400 miles --> 25.79%\n",
      " 400 < d <  600 miles --> 27.23%\n",
      " 600 < d <  800 miles --> 29.64%\n",
      " 800 < d < 1000 miles --> 33.53%\n",
      "1000 < d < 1200 miles --> 34.90%\n",
      "1200 < d < 1400 miles --> 37.50%\n",
      "1400 < d < 1600 miles --> 37.94%\n",
      "1600 < d < 1800 miles --> 39.88%\n",
      "1800 < d < 2000 miles --> 40.51%\n",
      "2000 < d < 2200 miles --> 42.10%\n",
      "2200 < d < 2400 miles --> 44.19%\n",
      "2400 < d < 2600 miles --> 42.82%\n",
      "2600 < d < 2800 miles --> 45.51%\n",
      "2800 < d < 3000 miles --> 44.89%\n",
      "3000 < d < 3200 miles --> 30.00%\n",
      "3200 < d < 3400 miles --> 47.90%\n",
      "3400 < d < 3600 miles --> 44.17%\n",
      "3600 < d < 3800 miles --> 44.89%\n",
      "3800 < d < 4000 miles --> 33.92%\n",
      "4000 < d < 4200 miles --> 43.88%\n",
      "4200 < d < 4400 miles --> 41.72%\n",
      "4400 < d < 4600 miles --> 39.44%\n",
      "4800 < d < 5000 miles --> 37.98%\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "for t in res:\n",
    "    print(\"{:4} < d < {:4} miles --> {:.2f}%\".format((t[0]-1) * 200, t[0] * 200, t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO visualization and plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty scores for each airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a weekly \"penalty\" score for each airport that depends on both \n",
    "# its incoming and outgoing flights. \n",
    "\n",
    "# The score adds 0.5 for each incoming flight that is more than 15 minutes\n",
    "# late, and 1 for each outgoing flight that is more than 15 minutes late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our group's data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an additional data analysis defined by your group\n",
    "\n",
    "# IDEE\n",
    "# qualcosa con gli altri delays? security, nas, carrier\n",
    "# qualche confronto tra carrier\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prima fare con un solo file come debug, poi mettere tutti"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
